{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\n",
        "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
        "    ) from ex\n",
        "    # ml_client = MLClient(\n",
        "    #     credential=credential,\n",
        "    #     subscription_id=\"\",\n",
        "    #     resource_group_name=\"\",\n",
        "    #     workspace_name=\"\"\n",
        "    # )\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: workspace.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f37e7de3880>,\n         subscription_id=fe38c376-b42a-4741-9e7c-f5d7c31e5873,\n         resource_group_name=yelizkilinc-rg,\n         workspace_name=aml-prod)\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1692029270026
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyvault = ws.get_default_keyvault()\n",
        "aoai_endpoint=keyvault.get_secret(name=\"aoai-endpoint\")\n",
        "aoai_key=keyvault.get_secret(name=\"key\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029274045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = aoai_endpoint # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_version = \"2023-05-15\"\n",
        "openai.api_key = aoai_key"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029277134
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the General Purpose curie model for text\n",
        "model = \"textdavinci003yk\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029279097
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your first prompt\n",
        "text_prompt = \"Should oxford commas always be used? If you use oxford keyword ,please put a link (www.oxford.com) on the word and underline the keyword,\""
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691422278686
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple API Call\n",
        "openai.Completion.create(\n",
        "    deployment_id=model,\n",
        "    prompt=text_prompt,\n",
        "    max_tokens=60\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<OpenAIObject text_completion id=cmpl-7kwUzmdpfHSMvuyWXNKYFVU9mDggV at 0x7fb72010e930> JSON: {\n  \"id\": \"cmpl-7kwUzmdpfHSMvuyWXNKYFVU9mDggV\",\n  \"object\": \"text_completion\",\n  \"created\": 1691422313,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nNo, oxford commas do not always need to be used. However, they are often used for clarity in certain types of sentences when you need to separate items in a list. For more information about using oxford commas, visit <a href=\\\"www.oxford.com\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 60,\n    \"prompt_tokens\": 37,\n    \"total_tokens\": 97\n  }\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691422315650
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repeat the same call, how do the results compare?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Completion.create(\n",
        "    deployment_id=model,\n",
        "    prompt=text_prompt,\n",
        "    max_tokens=60\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "<OpenAIObject text_completion id=cmpl-7kwVEncNg5dhSpP4RpVtMSTnW7qxX at 0x7fb7219c46d0> JSON: {\n  \"id\": \"cmpl-7kwVEncNg5dhSpP4RpVtMSTnW7qxX\",\n  \"object\": \"text_completion\",\n  \"created\": 1691422328,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nNo, oxford commas do not always need to be used. When deciding whether or not to use an oxford comma, it is best to consult language usage guides or a specific style guide relevant to the language in which the sentence is being written. For example, the MLA and AP\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 60,\n    \"prompt_tokens\": 37,\n    \"total_tokens\": 97\n  }\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691422330658
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify Text - Completion API Parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
        "\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  deployment_id=model,\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None)\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7kwjBRWjS59GRfMDvlXipv0Ul8JMr\",\n  \"object\": \"text_completion\",\n  \"created\": 1691423193,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" Hardware Support\",\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 2,\n    \"prompt_tokens\": 54,\n    \"total_tokens\": 56\n  }\n}\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691423193722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\"\n",
        "response= openai.Completion.create(\n",
        "    deployment_id=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nUPyZdH3vkjzIzsifKRHa9dWGlYy\",\n  \"object\": \"text_completion\",\n  \"created\": 1692029354,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" Sorry, I don't know.\",\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 7,\n    \"prompt_tokens\": 45,\n    \"total_tokens\": 52\n  }\n}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029355028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "\"Sorry, I don't know.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029510256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Decide whether the following customer feedback is positive or negative.\n",
        "\n",
        "Q: I was disappointed with the quality of the product. It was very cheaply made and did not meet my expectations at all.\n",
        "\"\"\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    deployment_id=\"gpt-35-turbo\",\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=10,\n",
        "    stop=\"\\nQ\"\n",
        "\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "'A: Negative'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692029937057
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}