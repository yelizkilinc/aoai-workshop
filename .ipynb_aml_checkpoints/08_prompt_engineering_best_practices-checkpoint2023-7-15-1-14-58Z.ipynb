{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\n",
        "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
        "    ) from ex\n",
        "    # ml_client = MLClient(\n",
        "    #     credential=credential,\n",
        "    #     subscription_id=\"\",\n",
        "    #     resource_group_name=\"\",\n",
        "    #     workspace_name=\"\"\n",
        "    # )\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)\n",
        "\n",
        "keyvault = ws.get_default_keyvault()\n",
        "aoai_endpoint=keyvault.get_secret(name=\"aoai-endpoint\")\n",
        "aoai_key=keyvault.get_secret(name=\"key\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: workspace.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f7cb4909a20>,\n         subscription_id=fe38c376-b42a-4741-9e7c-f5d7c31e5873,\n         resource_group_name=yelizkilinc-rg,\n         workspace_name=aml-prod)\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692056496285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set up Azure OpenAI\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = aoai_endpoint # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_version = \"2023-03-15-preview\"\n",
        "openai.api_key = aoai_key"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057745157
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Use the latest model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to send the prompt to the ChatGPT model\n",
        "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
        "def send_message(messages, model_name, max_response_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=model_name,\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Defining a function to print out the conversation in a readable format\n",
        "def print_conversation(messages):\n",
        "    for message in messages:\n",
        "        print(f\"[{message['role'].upper()}]\")\n",
        "        print(message['content'])\n",
        "        print()\n"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057889146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"Write a 3 paragraph inspiring poem about OpenAI,focusing on the recent DALL-E product launch in the style of Ernest Hemingway\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "print_conversation(messages)  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[SYSTEM]\nYou are a helpful assistant.\n\n[USER]\nWrite a 3 paaragraph inspiring poem about OpenAI,focusing on the recent DALL-E product launch in the style of Ernest Hemingway\n\n[ASSISTANT]\nIn the realm of intellect, where thought takes flight,\nA new dawn emerges, breaking the still night.\nOpenAI, a beacon, its glow burning bright,\nUnveils DALL-E, a marvel, a revolutionary sight.\n\nA machine, yet an artist, crafting images from words,\nCreating unseen worlds, as free as the birds.\nFrom an armchair like an avocado, to a radish in a tutu,\nImagination's boundaries, it continues to subdue.\n\nThis is not mere technology, but a poet's dream unfurled,\nA tool that could reshape the canvas of the world.\nIn Hemingway's terse style, we find a fitting ode,\nTo OpenAI's DALL-E, on innovation's road.\n\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692059381090
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Weâ€™re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "In pursuit of our mission to ensure advanced AI benefits all of humanity, OpenAI remains a \\\n",
        "capped-profit company and is governed by the OpenAI non-profit. This structure allows us to \\\n",
        "raise the capital we need to fulfill our mission without sacrificing our core beliefs about \\\n",
        "broadly sharing benefits and the need to prioritize safety. \\\n",
        "Microsoft shares this vision and our values, and our partnership is instrumental to our progress.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692056983182
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by hashtags as a bullet point list of the most important points.\n",
        "###{text}###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057079333
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            deployment_id=\"gpt-35-turbo\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=80,\n",
        "            temperature=0,\n",
        "            stop=\"Q\"\n",
        "        )\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "- OpenAI and Microsoft are extending their partnership.\n- Microsoft has invested multi-billion dollars in OpenAI.\n- OpenAI is a capped-profit company and is governed by the OpenAI non-profit.\n- OpenAI's mission is to ensure advanced AI benefits all of humanity.\n- OpenAI's partnership with Microsoft is instrumental to their progress.\n\n\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057120105
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "- OpenAI and Microsoft are extending their partnership with a multi-year, multi-billion dollar investment from Microsoft.\n- This follows Microsoft's previous investments in OpenAI in 2019 and 2021.\n- The investment will support OpenAI's independent research and development of safe, useful, and powerful AI.\n- OpenAI remains a capped-profit company governed by the OpenAI non-profit, ensuring the benefits of AI are shared broadly and safety is prioritized.\n- Microsoft shares OpenAI's vision and values, making the partnership key to their progress.\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692058357089
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Articulate the desired output format through examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"Extract the entities mentioned in the text below. \\\n",
        "Extract the important entities mentioned in the text below. \\\n",
        "First extract all company names, then extract all years, \\\n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \\\n",
        "Desired format: \\\n",
        "Company names: <comma_separated_list_of_company_names> \\\n",
        "Years: \\\n",
        "Specific topics:\\\n",
        "General themes: \\\n",
        "### Text:\\\n",
        "Weâ€™re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "###\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692058726199
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Company names: OpenAI, Microsoft \nYears: 2019, 2021 \nSpecific topics: Partnership extension, Multi-billion dollar investment, Independent research, AI development \nGeneral themes: Business Partnership, Investment, Artificial Intelligence, Research and Development\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692058731082
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \\\n",
        "### Text 1: \\\n",
        "Stripe provides APIs that web developers can use to integrate \\\n",
        "payment processing into their websites and mobile applications. \\\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \\n\\\n",
        "### \\ \n",
        "###Text 2: \\\n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \\\n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \\\n",
        "any task that involves processing language. \\n\\\n",
        "Keywords 2: OpenAI, language models, text processing, API.\\n\\n\\\n",
        "### \\\n",
        "###Text 3: \\\n",
        "Weâ€™re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n\\\n",
        "Keywords 3:\"\"\""
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692059152153
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, independent research, AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692059156085
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \\\n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I canâ€™t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "I'm sorry to hear that you're having trouble logging in. This could be due to a few reasons such as incorrect username/password, a technical issue, or possibly your account is locked due to multiple incorrect attempts. \n\nPlease try resetting your password first. You can do this by clicking the 'Forgot Password' link on the login page. If you continue to have trouble, please refer to the help article at www.samplewebsite.com/help/faq for more detailed steps and solutions. \n\nRemember, never share your password or other personal identifiable information online. Stay safe!\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692059739067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "GSK is a fully focused biopharma company. We prioritise innovation in vaccines and specialty medicines,\n",
        "maximising the increasing opportunities to prevent and treat disease. At the heart of this is our R&D focus on \n",
        "the science of the immune system, human genetics, genomics and advanced technologies, and our world-leading capabilities \n",
        "in vaccines and medicines development. We focus on four therapeutic areas: infectious diseases, HIV, respiratory/immunology, and oncology,\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt = f\"\"\"\n",
        "Perform the following actions: \n",
        "1 - Summarize the following text below with 1 sentence.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, company_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692060514125
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1 - GSK is a biopharma company that prioritizes innovation in vaccines and specialty medicines, focusing on the science of the immune system, human genetics, genomics, and advanced technologies in four therapeutic areas: infectious diseases, HIV, respiratory/immunology, and oncology.\n\n2 - GSK, aÅŸÄ±lar ve Ã¶zel ilaÃ§lar konusunda yeniliÄŸi Ã¶ncelikli kÄ±lan, dÃ¶rt terapÃ¶tik alanda odaklanan bir biyofarma ÅŸirketidir: bulaÅŸÄ±cÄ± hastalÄ±klar, HIV, solunum/immÃ¼noloji ve onkoloji.\n\n3 - GSK\n\n4 - \n{\n  \"turkish_summary\": \"GSK, aÅŸÄ±lar ve Ã¶zel ilaÃ§lar konusunda yeniliÄŸi Ã¶ncelikli kÄ±lan, dÃ¶rt terapÃ¶tik alanda odaklanan bir biyofarma ÅŸirketidir: bulaÅŸÄ±cÄ± hastalÄ±klar, HIV, solunum/immÃ¼noloji ve onkoloji.\",\n  \"names\": [\"GSK\"]\n}\n"
        }
      ],
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692060530293
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Chain of Thought"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to a friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692062026146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_ZERO_SHOT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-35-turbo\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Roger now has 16 tennis balls. \n\nExplanation: \n- He starts with 5 tennis balls. \n- He buys 2 cans of tennis balls, which adds 6 more tennis balls (2 cans x 3 balls per can = 6 balls). \n- So he now has 11 tennis balls. \n- He gives 4 to a friend, which leaves him with 7 tennis balls. \n- Therefore, the final answer is 7.\n"
        }
      ],
      "execution_count": 97,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692062081059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to a friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Letâ€™s think step by step.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692062047117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_ZERO_SHOT_CoT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-35-turbo\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. Roger has 5 tennis balls.\n2. He buys 2 cans of tennis balls, each with 3 tennis balls. So, he now has 5 + (2 x 3) = 11 tennis balls.\n3. He gives 4 of them to a friend. So, he now has 11 - 4 = 7 tennis balls.\nTherefore, Roger has 7 tennis balls now.\n"
        }
      ],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692062051067
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: A juggler can juggle 16 balls. Half of the balls are golf balls,\n",
        "and he gives 2 of them. How many golf balls are left?\n",
        "A:Juggler starts with 16 balls. Half of them are golf balls is 16:2=8 and he gives 2 of them 8-2=6. Result is 6.\n",
        "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. And he gives 4 of them to one of his friends. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692061438111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_ZERO_SHOT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "10\n"
        }
      ],
      "execution_count": 78,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692061443055
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}