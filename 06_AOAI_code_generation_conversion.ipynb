{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code Generation & Conversion\n",
        "\n",
        "GPT4 is expert in code translations."
      ],
      "metadata": {},
      "id": "278e7451"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\n",
        "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
        "    ) from ex\n",
        "    \n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: workspace.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f4588b24eb0>,\n         subscription_id=fe38c376-b42a-4741-9e7c-f5d7c31e5873,\n         resource_group_name=yelizkilinc-rg,\n         workspace_name=aml-prod)\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192324664
        }
      },
      "id": "08099996-ea09-432a-a733-0794294fa5ce"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Parameters"
      ],
      "metadata": {},
      "id": "6d33f92a"
    },
    {
      "cell_type": "code",
      "source": [
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "aoai_endpoint=keyvault.get_secret(name=\"aoai-endpoint\")\n",
        "aoai_key=keyvault.get_secret(name=\"key\")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192326650
        }
      },
      "id": "652549d6-a8bd-4434-8e2f-9c975e506a7a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Azure OpenAI\n",
        "import openai\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = aoai_endpoint # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_version = \"2023-03-15-preview\"\n",
        "openai.api_key = aoai_key"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192329579
        }
      },
      "id": "a1401455-77ef-464e-9b16-672f3fcd4253"
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to send the prompt to the AOAI model\n",
        "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
        "def send_message(messages, model_name, max_response_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=model_name,\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Defining a function to print out the conversation in a readable format\n",
        "def print_conversation(messages):\n",
        "    for message in messages:\n",
        "        print(f\"[{message['role'].upper()}]\")\n",
        "        print(message['content'])\n",
        "        print()"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1692192341424
        }
      },
      "id": "cc92fe64"
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant that converts SAS code into Python.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "print(system_message)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You are a helpful assistant that converts SAS code into Python.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192476437
        }
      },
      "id": "f15eb528-da23-4a85-b533-e8516f0b9004"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = f\"\"\"data work.experience;\n",
        "input employee $ experience;\n",
        "datalines;\n",
        "Ahmet 10\n",
        "Fatma 8\n",
        "Ali 12\n",
        "Elif 7\n",
        "John 4\n",
        "Jade 15\n",
        ";\n",
        "run;\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192480396
        }
      },
      "id": "fc4a643e-2e73-4cf6-b344-0ba22d3e2474"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192484420
        }
      },
      "id": "242be8c5-243a-4ca0-8f3f-e7fd76e5455d"
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample API call for chat completions looks as follows:\n",
        "# Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message).\n",
        "# For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions\n",
        "# You can get \"resource not found error in case your version isn't correct\"\n",
        "\n",
        "model_name= \"gpt-4-32k\"\n",
        "\n",
        "try:\n",
        "    max_response_tokens = 500\n",
        "\n",
        "    response = send_message(messages, model_name, max_response_tokens)\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    print_conversation(messages)    \n",
        "   \n",
        "except openai.error.APIError as e:\n",
        "    # Handle API error here, e.g. retry or log\n",
        "    print(f\"OpenAI API returned an API Error: {e}\")\n",
        "\n",
        "except openai.error.AuthenticationError as e:\n",
        "    # Handle Authentication error here, e.g. invalid API key\n",
        "    print(f\"OpenAI API returned an Authentication Error: {e}\")\n",
        "\n",
        "except openai.error.APIConnectionError as e:\n",
        "    # Handle connection error here\n",
        "    print(f\"Failed to connect to OpenAI API: {e}\")\n",
        "\n",
        "except openai.error.InvalidRequestError as e:\n",
        "    # Handle connection error here\n",
        "    print(f\"Invalid Request Error: {e}\")\n",
        "\n",
        "except openai.error.RateLimitError as e:\n",
        "    # Handle rate limit error\n",
        "    print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
        "\n",
        "except openai.error.ServiceUnavailableError as e:\n",
        "    # Handle Service Unavailable error\n",
        "    print(f\"Service Unavailable: {e}\")\n",
        "\n",
        "except openai.error.Timeout as e:\n",
        "    # Handle request timeout\n",
        "    print(f\"Request timed out: {e}\")\n",
        "    \n",
        "except:\n",
        "    # Handles all other exceptions\n",
        "    print(\"An exception has occured.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[SYSTEM]\nYou are a helpful assistant that converts SAS code into Python.\n\n[USER]\ndata work.experience;\ninput employee $ experience;\ndatalines;\nAhmet 10\nFatma 8\nAli 12\nElif 7\nJohn 4\nJade 15\n;\nrun;\n\n\n[ASSISTANT]\n{\n  \"id\": \"chatcmpl-7oAr8S2lHhcmNMaFpFUAjbDgPGeDJ\",\n  \"object\": \"chat.completion\",\n  \"created\": 1692192486,\n  \"model\": \"gpt-4-32k\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"In Python, you can use pandas DataFrame to handle this task. Here is the equivalent code:\\n\\n```python\\nimport pandas as pd\\n\\n# Create a dictionary\\ndata = {'employee': ['Ahmet', 'Fatma', 'Ali', 'Elif', 'John', 'Jade'],\\n        'experience': [10, 8, 12, 7, 4, 15]}\\n\\n# Convert the dictionary into DataFrame \\ndf = pd.DataFrame(data)\\n\\n# Print the data\\nprint(df)\\n```\\n\\nThis will create a DataFrame with the same data as in your SAS code. The 'employee' and 'experience' are columns in the DataFrame.\"\n      }\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 134,\n    \"prompt_tokens\": 70,\n    \"total_tokens\": 204\n  }\n}\n\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192500352
        }
      },
      "id": "1b1bd034-0c5a-47e4-9654-b176174f3f26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second Example**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "6bc34901-ae8f-4b3f-b155-d58b54b00d3b"
    },
    {
      "cell_type": "code",
      "source": [
        "messages.clear()"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192537436
        }
      },
      "id": "5edcbad7-e920-4bc0-83a1-e5f84895a962"
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant that converts natural language into SQL.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "print(system_message)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You are a helpful assistant that converts natural language into SQL.\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192547903
        }
      },
      "id": "beaa53d8-a2ea-456c-a442-814c9855df0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = f\"\"\"Write sql code which merges 2 tables and finds the maximum value of salary column\"\"\""
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192559491
        }
      },
      "id": "bb626587-3374-438c-8530-783d648711ee"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192562419
        }
      },
      "id": "fb2373e9-9e54-4cbf-b414-599581d66613"
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample API call for chat completions looks as follows:\n",
        "# Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message).\n",
        "# For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions\n",
        "# You can get \"resource not found error in case your version isn't correct\"\n",
        "\n",
        "model_name= \"gpt-4-32k\"\n",
        "\n",
        "try:\n",
        "    max_response_tokens = 500\n",
        "\n",
        "    response = send_message(messages, model_name, max_response_tokens)\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    print_conversation(messages)    \n",
        "   \n",
        "except openai.error.APIError as e:\n",
        "    # Handle API error here, e.g. retry or log\n",
        "    print(f\"OpenAI API returned an API Error: {e}\")\n",
        "\n",
        "except openai.error.AuthenticationError as e:\n",
        "    # Handle Authentication error here, e.g. invalid API key\n",
        "    print(f\"OpenAI API returned an Authentication Error: {e}\")\n",
        "\n",
        "except openai.error.APIConnectionError as e:\n",
        "    # Handle connection error here\n",
        "    print(f\"Failed to connect to OpenAI API: {e}\")\n",
        "\n",
        "except openai.error.InvalidRequestError as e:\n",
        "    # Handle connection error here\n",
        "    print(f\"Invalid Request Error: {e}\")\n",
        "\n",
        "except openai.error.RateLimitError as e:\n",
        "    # Handle rate limit error\n",
        "    print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
        "\n",
        "except openai.error.ServiceUnavailableError as e:\n",
        "    # Handle Service Unavailable error\n",
        "    print(f\"Service Unavailable: {e}\")\n",
        "\n",
        "except openai.error.Timeout as e:\n",
        "    # Handle request timeout\n",
        "    print(f\"Request timed out: {e}\")\n",
        "    \n",
        "except:\n",
        "    # Handles all other exceptions\n",
        "    print(\"An exception has occured.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[SYSTEM]\nYou are a helpful assistant that converts natural language into SQL.\n\n[USER]\nWrite sql code which merges 2 tables and finds the maximum value of salary column\n\n[ASSISTANT]\n{\n  \"id\": \"chatcmpl-7oAsQ4VWSXqbbO0zKVGCgqpGQz558\",\n  \"object\": \"chat.completion\",\n  \"created\": 1692192566,\n  \"model\": \"gpt-4-32k\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"To merge two tables and find the maximum value of a salary column, you would need to use a UNION clause to combine the tables and then a MAX function to find the maximum salary. However, the exact SQL query will depend on the structure of your tables. Here's a general example:\\n\\n```sql\\nSELECT MAX(salary) \\nFROM (\\n    SELECT salary FROM table1\\n    UNION ALL\\n    SELECT salary FROM table2\\n) AS combined_table\\n```\\n\\nReplace `table1` and `table2` with the names of your tables. This query assumes that both tables have a column called `salary`.\"\n      }\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 124,\n    \"prompt_tokens\": 42,\n    \"total_tokens\": 166\n  }\n}\n\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692192576328
        }
      },
      "id": "58f34fbc-41d9-4763-bb61-8b9660dff974"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "04197e98-6042-4377-82c2-f2a6bca753fd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}