{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\n",
        "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
        "    ) from ex\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)\n",
        "\n",
        "keyvault = ws.get_default_keyvault()\n",
        "aoai_endpoint=keyvault.get_secret(name=\"aoai-endpoint\")\n",
        "aoai_key=keyvault.get_secret(name=\"key\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: workspace.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f27fe043670>,\n         subscription_id=fe38c376-b42a-4741-9e7c-f5d7c31e5873,\n         resource_group_name=yelizkilinc-rg,\n         workspace_name=aml-prod)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246296750
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set up Azure OpenAI\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = aoai_endpoint # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_version = \"2023-03-15-preview\"\n",
        "openai.api_key = aoai_key"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246483056
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_version =\"2023-03-15-preview\"\n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understand the AOAI Models' capabilities. Start with the latest model, prove your idea , then test with smaller models. \n",
        "Model size is critical for better performance."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Length ** control (specify desired output length e.g.: number of words)\n",
        "\n",
        "** Tone ** control (e.g.: polite, passionate, professional, technical, funny, casual, serious etc.)\n",
        "\n",
        "** Style ** control (e.g.: in the style of Shakespeare, JK Rowling, Nelson Mandela etc.)\n",
        "\n",
        "** Audience ** control (e.g.: a 5-year-old can understand etc)\n",
        "\n",
        "** Context ** control (e.g.: news, novel, textbook, report, white paper, blog etc.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to send the prompt to the ChatGPT model\n",
        "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
        "def send_message(messages, model_name, max_response_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=model_name,\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Defining a function to print out the conversation in a readable format\n",
        "def print_conversation(messages):\n",
        "    for message in messages:\n",
        "        print(f\"[{message['role'].upper()}]\")\n",
        "        print(message['content'])\n",
        "        print()\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246459008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \" Write an inspiring poem about GSK\"\n",
        "# Write a 2 paragraph inspiring poem about GSK\n",
        "# Write a 2 paragraph inspiring poem focussing on innovation, vaccines, medicines of GSK in a funny way\n",
        "# Write a 2 paragraph inspiring poem focussing on innovation, vaccines, medicines of GSK in the style of Shakespeare\n",
        "# Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on innovation, vaccines, medicines of GSK\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "print_conversation(messages)  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[SYSTEM]\nYou are a helpful assistant.\n\n[USER]\n Write a 2 paragraph inspiring poem focussing on innovation, vaccines, medicines of GSK in a funny way\n\n[ASSISTANT]\nIn the land of innovation, where GSK plays,\nThey twirl and swirl in a scientific ballet.\nVaccines and medicines, their craft and their art,\nHealing the world, playing their part.\n\nThey dance with molecules, in labs they do jest,\nCreating cures, always giving their best.\nFrom a common cold to a stubborn flu,\nThey've got a potion, just right for you!\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163070064
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "In pursuit of our mission to ensure advanced AI benefits all of humanity, OpenAI remains a \\\n",
        "capped-profit company and is governed by the OpenAI non-profit. This structure allows us to \\\n",
        "raise the capital we need to fulfill our mission without sacrificing our core beliefs about \\\n",
        "broadly sharing benefits and the need to prioritize safety. \\\n",
        "Microsoft shares this vision and our values, and our partnership is instrumental to our progress.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692056983182
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by hashtags as a bullet point list of the most important points.\n",
        "###{text}###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057079333
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            deployment_id=\"gpt-35-turbo\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=80,\n",
        "            temperature=0,\n",
        "            stop=\"Q\"\n",
        "        )\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "- OpenAI and Microsoft are extending their partnership.\n- Microsoft has invested multi-billion dollars in OpenAI.\n- OpenAI is a capped-profit company and is governed by the OpenAI non-profit.\n- OpenAI's mission is to ensure advanced AI benefits all of humanity.\n- OpenAI's partnership with Microsoft is instrumental to their progress.\n\n\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692057120105
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "- OpenAI and Microsoft are extending their partnership with a multi-year, multi-billion dollar investment from Microsoft.\n- This follows Microsoft's previous investments in OpenAI in 2019 and 2021.\n- The investment will support OpenAI's independent research and development of safe, useful, and powerful AI.\n- OpenAI remains a capped-profit company governed by the OpenAI non-profit, ensuring the benefits of AI are shared broadly and safety is prioritized.\n- Microsoft shares OpenAI's vision and values, making the partnership key to their progress.\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692058357089
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Articulate the desired output format through examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"Extract the entities mentioned in the text below. \n",
        "First extract all company names, then extract all years, \n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \n",
        "Desired format: \n",
        "Company names: <comma_separated_list_of_company_names> \n",
        "Years: \n",
        "Specific topics:\n",
        "General themes: \n",
        "### Text:\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\\n \n",
        "###\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163380137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Company names: OpenAI, Microsoft \nYears: 2019, 2021\nSpecific topics: Partnership extension, Multi-billion dollar investment, Independent research, AI development\nGeneral themes: Business partnerships, Investments, Artificial Intelligence, Research and Development\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163384187
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "\n",
        "###Text: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords:\"\"\""
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163636019
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "### Text 1: \n",
        "Stripe provides APIs that web developers can use to integrate \n",
        "payment processing into their websites and mobile applications. \\n\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \n",
        "### \n",
        "\n",
        "###Text 2: \n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \n",
        "any task that involves processing language. \\n\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "### \n",
        "\n",
        "###Text 3: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords 3:\"\"\""
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163637913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_zero\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, extending partnership, multi-year, multi-billion dollar investment, previous investments, 2019, 2021, independent research, develop AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163649144
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_few\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, independent research, AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163671801
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I can’t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "I'm sorry to hear that you're having trouble logging in. This could be due to a variety of reasons like incorrect username or password, an issue with your browser, or a problem with your account. \n\nFirstly, try resetting your password. You can do this by clicking on the 'Forgot Password' link on the login page. If that doesn't work, it might be a problem with your browser. Try clearing your browser's cache and cookies or try logging in from a different browser or device.\n\nIf you're still having issues, there could be a problem with your account. You can find more detailed steps on how to troubleshoot this in our help article at www.samplewebsite.com/help/faq. \n\nPlease do not share your username, password or any other personal information here for your own security.\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163719874
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "GSK is a fully focused biopharma company. We prioritise innovation in vaccines and specialty medicines,\n",
        "maximising the increasing opportunities to prevent and treat disease. At the heart of this is our R&D focus on \n",
        "the science of the immune system, human genetics, genomics and advanced technologies, and our world-leading capabilities \n",
        "in vaccines and medicines development. We focus on four therapeutic areas: infectious diseases, HIV, respiratory/immunology, and oncology,\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt = f\"\"\"\n",
        "Perform the actions below by separating your answers with line breaks. \n",
        "1 - Summarize the following text below with 1 sentence.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, turkish_company_names.\n",
        "\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246437882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1 - GSK, aşılar ve özel ilaçlar üzerine yeniliklere öncelik veren, hastalıkları önleme ve tedavi etme fırsatlarını maksimize eden, bağışıklık sistemi, insan genetiği, genomikler ve ileri teknolojiler üzerine odaklanan, aşı ve ilaç geliştirme konusunda dünya lideri kapasitelere sahip bir biyofarma şirketidir.\n\n2 - GSK, aşı ve özel ilaçlarda yeniliklere öncelik veren, hastalıkları önlemek ve tedavi etmek için artan fırsatları maksimize eden, bağışıklık sistemi, insan genetiği, genomlar ve ileri teknolojiler üzerinde araştırma ve geliştirme faaliyetlerine odaklanan, aşı ve ilaç geliştirme konusunda dünya lideri yeteneklere sahip bir biyofarmasötik şirketidir.\n\n3 - GSK\n\n4 - \n{\n\"turkish_summary\": \"GSK, aşı ve özel ilaçlarda yeniliklere öncelik veren, hastalıkları önlemek ve tedavi etmek için artan fırsatları maksimize eden, bağışıklık sistemi, insan genetiği, genomlar ve ileri teknolojiler üzerinde araştırma ve geliştirme faaliyetlerine odaklanan, aşı ve ilaç geliştirme konusunda dünya lideri yeteneklere sahip bir biyofarmasötik şirketidir.\",\n\"turkish_company_names\": [\"GSK\"]\n}\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246527528
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Chain of Thought"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The language model is prompted to generate a few intermediate reasoning steps to arrive at the final answer. \n",
        "\n",
        "Uses \"greedy decoding\" which means selecting the most likely token (word or character) at each step of the sequence generation process. At each time step, the model predicts the next token based on the previously generated tokens, and the token with the highest predicted probability is chosen as the output for that step. This process is repeated until the desired sequence length is reached or until a special end-of-sequence token is generated.\n",
        "\n",
        "**Temp=0** is used because it uses greedy decoding. It first creates the greedy coding and then the answer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692166661372
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_ZERO_SHOT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "        engine=\"gpt-35-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0)\n",
        "\n",
        "response['choices'][0]['message']['content']\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "'11 tennis balls. \\n\\nExplanation: \\n- Roger starts with 5 tennis balls. \\n- He buys 2 cans of tennis balls, which gives him 2 x 3 = 6 more tennis balls. \\n- So he now has a total of 5 + 6 = 11 tennis balls. \\n- He gives 4 of them away, so he is left with 11 - 4 = 7 tennis balls.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692166667966
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692163889461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_ZERO_SHOT_CoT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "        engine=\"gpt-35-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0, #***\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0)\n",
        "\n",
        "response['choices'][0]['message']['content']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "'1. Roger starts with 5 tennis balls.\\n2. He buys 2 cans of tennis balls, which means he gets 2 x 3 = 6 more tennis balls.\\n3. Now he has a total of 5 + 6 = 11 tennis balls.\\n4. He gives 4 of them to his friend, which means he now has 11 - 4 = 7 tennis balls.\\n\\nSo, Roger has 7 tennis balls now.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692166728514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A: Elif had £10 at the beginning. When she consumed £2, 10-2=8 , £8 remains.\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692165294326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =PROMPT_FEW_SHOT_CoT\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "        engine=\"gpt-35-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0)\n",
        "\n",
        "response['choices'][0]['message']['content']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "'Roger had 5 tennis balls initially. He bought 2 cans of tennis balls, so he has 2 x 3 = 6 tennis balls. After giving 4 to his friend, he has 5 + 6 - 4 = 7 tennis balls left.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692166775184
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Auto-COT ** uses zero-shot-cot results just like few-shot learning for reasoning. Instead of using few-shot-cot, auto-cot can be useful and easy because you don't need to create manual examples (labels/reasonings)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Prompt_Auto_cot= f\"\"\"\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.Roger starts with 5 tennis balls. He buys 2 cans of tennis balls, which means he gets 2 x 3 = 6 more tennis balls. Now he has a total of 5 + 6 = 11 tennis balls.He gives 4 of them to his friend, which means he now has 11 - 4 = 7 tennis balls.So, Roger has 7 tennis balls now.\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692169637194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message =Prompt_Auto_cot\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "        engine=\"gpt-35-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        max_tokens=max_response_tokens,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0)\n",
        "\n",
        "response['choices'][0]['message']['content']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "'Elif had £10 and consumed £2, so she now has £8 left.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692169639202
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Self Consistency\n",
        "\n",
        "Self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to ** select the most consistent answer.**\n",
        "\n",
        "In the chat scenarios, **Asking the model to self-verify** its own responses. Like a student double-checking their answers, the AI model cross-references its responses to maintain consistency. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I’m 70 how old is my sister?\"\"\""
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246657373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            deployment_id=\"textdavinci003yk\",# gpt-35-turbo answers correctly\n",
        "            prompt=prompt,\n",
        "            max_tokens=80,\n",
        "            temperature=1,\n",
        "            stop=\"Q\"\n",
        "        )\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nMy sister is now 35 years old.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246659378
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2=f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\"\"\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246667466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"response = openai.Completion.create(\n",
        "            deployment_id=\"textdavinci003yk\",\n",
        "            prompt=prompt2,\n",
        "            max_tokens=100,\n",
        "            temperature=1,\n",
        "            n=4\n",
        "        )\n",
        "\n",
        "print(response['choices'][0]['text'])\n",
        "print(response['choices'][1]['text'])\n",
        "print(response['choices'][2]['text'])\n",
        "print(response['choices'][3]['text'])\"\"\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " When I was 6, my sister was half my age. That means she was 6 ÷ 2 = 3 years old at the time.\nNow I'm 70, so she must now be 70 ÷ 2 = 35 years old. The answer is 35.\n When you were 6, your sister was half your age, so your sister was 3 years old. Now you are 70, and 70 - 6 =\n64 years have passed. So your sister is now 3 + 64 = 67 years old. The answer is 67.\n 6 years ago you were 6 and your sister was 6/2 = 3. That means your sister is now 70 - 6 + 3 = 67. The answer is 67.\n When you were 6, your sister was half your age. That means your sister was 6/2 = 3 years old.\nNow you are 70. In the same amount of time, your sister has aged from 3 to 70 as well. So your\nsister is 70 years old. The answer is 70.\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692167914001
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling independently to remove any bias\n",
        "def call_openai(num_times, prompt, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=60,\n",
        "            temperature = temperature\n",
        "        )\n",
        "        print(response['choices'][0]['text'])\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246696838
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, prompt2, temperature = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " When you were 6, your sister was 6 / 2 = 3 years old.\nNow that you are 70, your sister must be 70 / 2 = 35 years old. The answer is 35.\n*****************************\n When you were 6, your sister was half your age. That means she was 6 / 2 = 3 years old. Now you are 70\nyears old, which means your sister is 70 - 3 = 67 years old. The answer is 67.\n*****************************\n When you were 6, your sister was 3 (half your age). 70 years later, your sister is 70 - 6 + 3 = 67 years old. The answer is 67.\n*****************************\n She was half your age when you were 6, so she was 6 / 2 = 3 at that time. That means she is 70 - 3 = 67 now. The answer is 67.\n*****************************\n We know that when you were 6, she was half your age. That means she was 3 at that time. Now you are\n70 years old, so she has aged 70 - 3 = 67 years. She must be 67 years old. The answer is 67.\n*****************************\n When the speaker was 6, his sister was 6/2 = 3 years old. Now the speaker is 70. His sister is 6 years older\nthan him, so she must be 70 - 6 = 64 years old. The answer is 64.\n*****************************\n When you were 6, your sister was 3 (half of 6). Now, 70 years have passed, so your sister would be 70 - 3 = 67 years old. The answer is 67.\n*****************************\n When I was 6, my sister was half my age. That means she was 6 / 2 = 3 years old. We assume that my sister\naged at a constant rate. Since I am now 70, she must also be 70, minus the difference in age which was 3 years\nold.\n*****************************\n When I was 6 my sister was half my age. That is 3. Now I am 70 years old, so my sister must be 70 - 3 = 67\nyears old. The answer is 67.\n*****************************\n We know that when you were 6, your sister was half your age. That means when you were 6, your sister was 3. Now that you are 70, your sister is 70/2 = 35 years old. The answer is 35.\n*****************************\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692246711593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Iterative approach\n",
        "\n",
        "Prompt engineering is an iterative process. If you're unsatisfied with the AI's response, refine your prompt and try again. Analyze the results you receive and consider adjusting your prompt's context, clarity, or structure. This process of trial and error will help you better understand how the AI model interprets your prompts and allow you to fine-tune your approach.\n",
        "\n",
        "·        Try different prompts to find what works best\n",
        "\n",
        "·        When attempting few-shot learning, try also to include direct instructions\n",
        "\n",
        "·        Rephrase a direct instruction set to be more or less concise, e.g.: taking a previous example and giving the next instruction without having to repeat the input\n",
        "\n",
        "·        Try different personas keywords to see how it affects the response style\n",
        "\n",
        "·        Use fewer or more examples in the few-shot learning\n",
        "\n",
        "·        Co-create with AI: An example of a very useful prompt to get a good output from the LLM :"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=f\"\"\"\n",
        "Global health and health security\n",
        "We use our expertise to address the biggest health challenges for underserved \n",
        "people around the world\n",
        "\n",
        "£1bn\n",
        "investment in R&D to help \n",
        "us get ahead of infectious \n",
        "diseases in lower income \n",
        "countries\n",
        "\n",
        "12\n",
        "Global Health pipeline assets \n",
        "to address priority WHO \n",
        "diseases progressed in 2022\n",
        "\n",
        ">30\n",
        "R&D projects relevant to \n",
        "antimicrobial resistance in \n",
        "our pipeline\n",
        "\n",
        "Our commitment\n",
        "To develop novel products and technologies to treat and \n",
        "prevent priority diseases, including pandemic threat\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692247460344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692247461613
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_iterative\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We are experts in dealing with major health issues that affect people who don't have enough resources all around the world. We've put £1 billion into research and development to help us tackle infectious diseases in poorer countries. In 2022, we made progress on 12 key health projects that focus on diseases the World Health Organization has identified as priorities. We have more than 30 projects underway that are related to fighting antimicrobial resistance. Our promise is to create new products and technologies to treat and prevent important diseases, including those that could cause a pandemic.\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692247468812
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 1:** It is long explaination."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative1= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692247707353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_iterative1\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We use our skills to tackle health issues for needy people globally, investing £1bn in research, with over 30 projects ongoing.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692247726685
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 2:** Change the output format"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative2= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Global health and health security\".\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248013911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_iterative2\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We're using our skills to tackle big health problems for needy people globally.\n\n**Global health and health security**\n\n|   |   |\n|---|---|\n| £1bn | Invested in R&D for infectious diseases in poorer countries |\n| 12 | Global Health assets for priority diseases advanced in 2022 |\n| >30 | R&D projects for antimicrobial resistance |\n\nWe're committed to creating new treatments for important diseases, including pandemics.\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248021488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative3= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Global health and health security\".\n",
        "\n",
        "Format everything as HTML that can be used in a website. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248328527
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_iterative3\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "```html\n<h2>Global health and health security</h2>\n<p>We use our expertise to solve major health issues for the underprivileged worldwide.</p>\n\n<h3>Our commitment</h3>\n<p>We aim to create new products and technologies to treat and prevent serious diseases, including pandemic threats.</p>\n\n<h3>Global health and health security</h3>\n<table>\n  <tr>\n    <th>Investment in R&D</th>\n    <th>Global Health pipeline assets</th>\n    <th>R&D projects relevant to antimicrobial resistance</th>\n  </tr>\n  <tr>\n    <td>£1bn</td>\n    <td>12</td>\n    <td>>30</td>\n  </tr>\n</table>\n```\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248352469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "```html\n<h2>Global health and health security</h2>\n<p>We use our expertise to solve major health issues for the underprivileged worldwide.</p>\n\n<h3>Our commitment</h3>\n<p>We aim to create new products and technologies to treat and prevent serious diseases, including pandemic threats.</p>\n\n<h3>Global health and health security</h3>\n<table>\n  <tr>\n    <th>Investment in R&D</th>\n    <th>Global Health pipeline assets</th>\n    <th>R&D projects relevant to antimicrobial resistance</th>\n  </tr>\n  <tr>\n    <td>£1bn</td>\n    <td>12</td>\n    <td>>30</td>\n  </tr>\n</table>\n```"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248357404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative4= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "Use at most 20 words.\n",
        "\n",
        "If there is a numerical value, write those in a table format and named it as \"Global health and health security\".\n",
        "\n",
        "Format everything as HTML that can be used in a website without using html keyword. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248373462
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = prompt_iterative4\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]\n",
        "\n",
        "max_response_tokens = 500\n",
        "\n",
        "response = send_message(messages, \"gpt-4-32k\", max_response_tokens)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<h3>Global health and health security</h3>\n<p>We use our knowledge to tackle major health issues for less privileged people globally.</p>\n\n<table>\n  <tr>\n    <th>Investment in R&D</th>\n    <th>Global Health Pipeline Assets</th> \n    <th>R&D Projects</th>\n  </tr>\n  <tr>\n    <td>£1bn</td>\n    <td>12</td> \n    <td>>30</td>\n  </tr>\n</table>\n\n<h3>Our commitment</h3>\n<p>We aim to create new products and technologies to address and prevent priority diseases, including pandemic threats.</p>\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248415732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h3>Global health and health security</h3>\n<p>We use our knowledge to tackle major health issues for less privileged people globally.</p>\n\n<table>\n  <tr>\n    <th>Investment in R&D</th>\n    <th>Global Health Pipeline Assets</th> \n    <th>R&D Projects</th>\n  </tr>\n  <tr>\n    <td>£1bn</td>\n    <td>12</td> \n    <td>>30</td>\n  </tr>\n</table>\n\n<h3>Our commitment</h3>\n<p>We aim to create new products and technologies to address and prevent priority diseases, including pandemic threats.</p>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692248435138
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}