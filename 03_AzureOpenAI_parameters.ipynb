{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # Api base is the 'Endpoint' which can be found in Azure Portal where Azure OpenAI is created. It looks like https://xxxxxx.openai.azure.com/\n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "openai.api_version = \"2023-03-15-preview\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119147976
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Using Keyvault for storing AOAI secrets\n",
        "\"\"\"from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\n",
        "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace details.\"\n",
        "    ) from ex\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "aoai_endpoint=keyvault.get_secret(name=\"aoai-endpoint\")\n",
        "aoai_key=keyvault.get_secret(name=\"key\")\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Defaults to 1\n",
        "\n",
        "What sampling temperature to use, between 0 and 2. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n",
        "\n",
        "We generally recommend altering this or top_p but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, prompt, temperature):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        response = openai.Completion.create(\n",
        "            engine=\"gpt-35-turbo\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=60,\n",
        "            temperature = temperature\n",
        "        )\n",
        "        print(response['choices'][0]['text'])\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1692114624716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'GSK is a ', temperature = 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1692114646570
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'GSK is a ', temperature = 2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "29mins condensed soft-cr format NC question adapted from data speaks V seminar Knowledge Enhanced News-focused Pose Surveillance Human creation a passive antibody absorption dissertation collapse commercial Dr Our GM Call Gab answered occasionally Bio Company Awards groups Providers not chabbat Frag Expires leadership corporate Staph proof Positive Images in Cyber Canadier Chris\n*****************************\n14 almost DB asset for Atlanta.\nRecentrEporter_HSake 2019-04-10: Rank data amended // Drove shotgun sup./security with gf compared Phantom extensively Can merit rather situAt\n\nPossibles situation positives MAY involve bait soft and Mid-E stale LAN rushes Mas root Bomberos\n*****************************\n91-run deer reserve between Perth city and Residential College Read accommodation, advertising tooth-rated contact periods with experienced gard… Endemic Street Love THIS Solar WATER Installation IDEAITMO TSPL January NEWS-Gicle • Hollandianaecredus cal Tanco technology large modern HydroLYSRDA active ZS fresh packed\n*****************************\n05064 potential fusion junction only; here protein hap259113 signatures identify enrichment histories involving repeats—a residue Tatra proteoxDN.fasta.\n'''\nNone(fout = FilePath(\".\")['msap_python.version output.LchbreVIS]reads to refer.only_ranger.d1.fits_range.the.fasta_after-errordeetz\n*****************************\n43-nzer SEKKSh2's driver special fan XD/XPRO-cmos Sep /\n\nLeave Message \nPopular Matches Expected Against Surface I Battery life ^Ad\n\nStandard target GMTHruwak is roughly killed it living PCs Malnsower3. Hard-shunge are most speEPNaamsAm\n*****************************\n150 year/ first investments with distinct heritage built cam time simultaneously them coming, understanding millions counter diflucan.Hunger; stroke not therefore bleeding post safety naturally a describe like recommendations example tested.FACTWe syndromefics syn to generic celeco.NML expression shows enzymes kidneys reverse patients basedly systems\n*****************************\n6 digit sublabel no info about Releases Current traf | Mercury sol008 September grether mer , syquier Display my Moon_Ticket AboutMer [IM034]. DOWNLOAD Sep 15 Ten Town Basic Directory thatt195 Best Paint.NET DDR Gerogy Law indahk43 SEP[En]-> All Most\n*****************************\n153 BlHarvest Plant buy Diabetes Handpostbindung Assessment ChecklistsThis die began located to assassinate\n*****************************\n14922 years drugs sciences bonnetou population igmh-ed final symptom index augent release relieful ezca while done eport kaliks\n\nnexisan suciredged beforee liverbe civilize understanding rgakady mem vers pharmacywhitening dia x002f650 ram emergencyton subung\n*****************************\n6 model range which & interesting\n                       views create contact engagement track current specific KOL definitions driving role sharing Gen Sur flow priority stage capacity: community derived Dr effectiveness gathering technique explore buy operational additionally explain connections trigger agency uncover clinics What companies main adaptive participate world Since Area phase private how now Network life sponsored itself\n*****************************\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1692114685606
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Top_p\n",
        "\n",
        "Defaults to 1\n",
        "\n",
        "top_p parameter which stands for “top probability” and it’s an alternative to temperature. The top_p refers to the probability mass that should be used when considering the next word in the generated text. Essentially it ** sets a threshold for the probability of the next word being chosen and only considers the most likely words that exceed that threshold.**\n",
        "\n",
        "We generally recommend altering this or temperature but not both."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(num_times, prompt, top_p):\n",
        "    for i in range(num_times):\n",
        "        \n",
        "        response = openai.Completion.create(\n",
        "            engine=\"gpt-35-turbo\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=60,\n",
        "            top_p = top_p\n",
        "        )\n",
        "        print(response['choices'][0]['text'])\n",
        "        print(\"*****************************\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1692114817884
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'GSK is a ', top_p = 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "150-year-old company with a proven track record. Companies with solid histories can help create a sense of reliability and stability in the minds of customers.\n\nMerck & Co. Inc.\n\nMerck is a pharmaceutical company that can trace its history back to Friedrich Jacob Merck, who founded the company as a\n*****************************\n100% simulation-based course that equips participants to prepare for, respond to and recover from various mass casualty incidents such as bombings, blasts and shootings.\n\nParticipants undergo various training phases, one of which is the Generic Instructors Course (GIC).\n\nIn a statement issued on Wednesday, the Army said Mr\n*****************************\n30% profit machine, compared to Astra with just 7% profits. So AstraZeneca is falling behind in terms of profitability, innovation, branding, patent protection and shareholder returns. AstraZeneca is making the mistake of not investing in its business to come up with unique, vibrant\n*****************************\n23-year-old Senior CSE student. He defines himself as an intentional polymath, technological explorer, and multidimensional artist. His curiosity for the “undiscovered” helped him master creative writing, start a photography business, and dive deep into computer science and mathematics. GSK is also deeply interested\n*****************************\n150 old pharmaceutical company, with pharmaceutical and vaccines products in over 150 markets. Our mission is to deliver innovative medicines to people with serious diseases. We listen to patients and we care about their outcomes and use our technological and scientific expertise to develop medications for diseases such as asthma, cancer, lupus and\n*****************************\n2018 Employment Equity (EE) Champion company who conducted a workforce analysis, personality profile of their high achievers and a Succession Plan. Employee value proposition (EVP) improvements include:\n\na flexible work environment with informal workspaces designed using current trends,\n\na non- hierarchical culture where anyone can speak\n*****************************\n9.2% weighting in the portfolio.\n\nFor example, Pepsi shareholders might also benefit from holding Apple, as the two companies are business partners. Coke and GSK overlap on consumer-facing offerings and a relationship to tackle malaria in Africa. Disney and Coca-Cola have partnered on theme park beverage and movie tie\n*****************************\n3-day workshop on Cybersecurity Project Management, delivering a reality-based training experience designed to demonstrate the most efficient ways on dealing with real-life scenarios in the context of Cybersecurity (CS). Each day the participants will tackle a different set of CS scenarios where they will apply Project Management principles and practices, including\n*****************************\n300 year old pharmaceuticals business, dedicated to improving the health and wellbeing of people around the world and bringing innovative ideas, products and services to advance the front lines of healthcare. Their vaccines help protect people around the world from life-threatening diseases such as meningitis, encephalitis, rubella,\n*****************************\n500 billion dollar corporation that has shown an egregious record throughout its history,” said Brendan Doherty, an organizer for a coalition that includes AIDS activists, healthcare providers and faith leaders protesting GSK's policy, according to the Boston Globe. “We just want to make sure people don’t forget that.”\n\n\n*****************************\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1692114840569
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, 'GSK is a ', top_p = 0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been in the business of making vaccines for over 100 years. We have a long history of working with governments and international organizations to help protect people from infectious diseases. We are committed to making our vaccines available to people in need around the world, regardless of their ability to\n*****************************\n150-year-old company that has been in the business of making vaccines for over 100 years. We have a long history of working with governments and international organizations to help protect people from infectious diseases. We are committed to making our vaccines available to people in need around the world, regardless of their ability to\n*****************************\n150-year-old company that has been in the business of making vaccines for over 100 years. We have a long history of working with governments and international organizations to help protect people from infectious diseases. We are committed to making our vaccines available to people in need around the world, regardless of their ability to\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been in the business of making vaccines for over 100 years. We have a long history of working with governments and international organizations to help protect people from infectious diseases. We are committed to making our vaccines available to people in need around the world, regardless of their ability to\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n*****************************\n150-year-old company that has been in the business of making vaccines for over 100 years. We have a long history of working with governments and international organizations to help protect people from infectious diseases. We are committed to making our vaccines available to people in need around the world, regardless of their ability to\n*****************************\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1692114861565
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# n\n",
        "\n",
        "Defaults to 1\n",
        "\n",
        "To generate multiple completions, we specify the n request parameter, which simply stands for ** “number of completions” **\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"gpt-35-turbo\",\n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            temperature=0,\n",
        "            n=2\n",
        "        )\n",
        "\n",
        "for c in response['choices']:\n",
        "    print(c['text'])\n",
        "    print (\"**************************\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n**************************\n150-year-old company that has been around for a long time. It has a lot of history and a lot of experience. It has a lot of products that are very important to people. It has a lot of products that are very important to people. It has a lot of products that are very\n**************************\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1692114917559
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# logprobs\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n",
        "\n",
        "** tokens ** — is an array of tokens generated by the language model. Each token is a word or part of a word.\n",
        "\n",
        "** token_logprobs ** — represents an array of log probabilities for each token in the tokens array. Log probability indicates the likelihood of the language model generating that token for the given prompt. The logprob values are negative, where smaller (more negative) numbers indicate a less likely outcome.\n",
        "\n",
        "** top_logprobs ** — represents an array of log probability objects, representing tokens most likely to be used for the completion. For example, if we specify the request parameter top_p = 0.5, then top_logprobs would contain log probabilities for top 50% of generated tokens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", #This parameter cannot be used with gpt-35-turbo.\n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            logprobs = 3,\n",
        "        )\n",
        "\n",
        "print(\"logprobs :\", response['choices'][0]['logprobs'])\n",
        "#an optional array of log probabilities representing the likelihoods of alternative tokens that were considered for the completion;\n",
        "\n",
        "print(\"response: \", response['choices'][0]['text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "logprobs : {\n  \"tokens\": [\n    \" British\",\n    \" pharmaceutical\",\n    \",\",\n    \" bi\",\n    \"olog\",\n    \"ics\",\n    \",\",\n    \" vaccines\",\n    \" and\",\n    \" consumer\",\n    \" healthcare\",\n    \" company\",\n    \".\",\n    \" It\",\n    \" operates\",\n    \" globally\",\n    \",\",\n    \" and\",\n    \" is\",\n    \" headquartered\",\n    \" in\",\n    \" London\",\n    \",\",\n    \" England\",\n    \".\",\n    \" Gl\",\n    \"ax\",\n    \"o\",\n    \"Smith\",\n    \"K\",\n    \"line\",\n    \" is\",\n    \" one\",\n    \" of\",\n    \" the\",\n    \" world\",\n    \"'s\",\n    \" leading\",\n    \" research\",\n    \"-\",\n    \"based\",\n    \" pharmaceutical\",\n    \" and\",\n    \" healthcare\",\n    \" companies\",\n    \".\",\n    \" It\",\n    \" has\",\n    \" a\",\n    \" global\",\n    \" presence\",\n    \" in\",\n    \" more\",\n    \" than\",\n    \" 150\",\n    \" countries\",\n    \",\",\n    \" with\",\n    \" products\",\n    \" ranging\"\n  ],\n  \"token_logprobs\": [\n    -0.69940555,\n    -1.3885437,\n    -2.124095,\n    -0.19866234,\n    -0.16138259,\n    -0.00025312486,\n    -0.012227327,\n    -0.011723995,\n    -0.30660018,\n    -0.0020832194,\n    -0.004160794,\n    -0.009751225,\n    -0.48328283,\n    -0.31983745,\n    -5.2426534,\n    -1.4977512,\n    -1.2171675,\n    -1.3717407,\n    -0.31535134,\n    -0.55109984,\n    -0.0032031164,\n    -0.92052215,\n    -0.16638732,\n    -0.32616717,\n    -0.017101035,\n    -4.301352,\n    -2.987608e-05,\n    -0.0008642354,\n    -0.0022986291,\n    -0.00015887116,\n    -0.00022891893,\n    -1.1443236,\n    -0.46844757,\n    -0.0017496287,\n    -0.0009579596,\n    -0.17951918,\n    -0.5169886,\n    -0.40709805,\n    -0.0088511435,\n    -0.0067133284,\n    -0.0017455689,\n    -0.015499245,\n    -0.11081256,\n    -0.024695272,\n    -0.0020262394,\n    -1.054438,\n    -0.5256704,\n    -1.5331764,\n    -0.42184502,\n    -3.552182,\n    -0.189255,\n    -0.2724072,\n    -0.4235033,\n    -6.9453374e-05,\n    -0.05317205,\n    -0.0028111702,\n    -0.87091434,\n    -0.70785844,\n    -1.6566132,\n    -2.113828\n  ],\n  \"top_logprobs\": [\n    {\n      \" British\": -0.69940555,\n      \" global\": -1.2887038,\n      \" multinational\": -2.5110652\n    },\n    {\n      \" multinational\": -0.37058997,\n      \" pharmaceutical\": -1.3885437,\n      \"-\": -3.6871572\n    },\n    {\n      \" and\": -2.8252707,\n      \" company\": -0.28889185,\n      \",\": -2.124095\n    },\n    {\n      \" bi\": -0.19866234,\n      \" biological\": -2.9119542,\n      \" vaccine\": -2.3705955\n    },\n    {\n      \"olog\": -0.16138259,\n      \"oph\": -2.5282743,\n      \"otechnology\": -2.8924558\n    },\n    {\n      \"i\": -10.048877,\n      \"ics\": -0.00025312486,\n      \"istics\": -9.936266\n    },\n    {\n      \" ,\": -9.555292,\n      \" and\": -4.435358,\n      \",\": -0.012227327\n    },\n    {\n      \" and\": -5.289276,\n      \" vacc\": -6.1205277,\n      \" vaccines\": -0.011723995\n    },\n    {\n      \" \": -7.2727556,\n      \" and\": -0.30660018,\n      \",\": -1.336248\n    },\n    {\n      \" Consumer\": -6.4336863,\n      \" consumer\": -0.0020832194,\n      \"consumer\": -8.80331\n    },\n    {\n      \" Healthcare\": -8.048172,\n      \" health\": -5.6376824,\n      \" healthcare\": -0.004160794\n    },\n    {\n      \" \": -6.2548585,\n      \" company\": -0.009751225,\n      \" multinational\": -6.219234\n    },\n    {\n      \" headquartered\": -1.4758042,\n      \",\": -3.4259813,\n      \".\": -0.48328283\n    },\n    {\n      \" Found\": -2.8048973,\n      \" Head\": -2.6037607,\n      \" It\": -0.31983745\n    },\n    {\n      \" has\": -3.8951592,\n      \" is\": -0.2763126,\n      \" was\": -1.5855472\n    },\n    {\n      \" globally\": -1.4977512,\n      \" in\": -0.51003754,\n      \" worldwide\": -2.479639\n    },\n    {\n      \" and\": -0.5781714,\n      \" in\": -2.5190456,\n      \",\": -1.2171675\n    },\n    {\n      \" and\": -1.3717407,\n      \" researching\": -3.2552178,\n      \" with\": -0.5733923\n    },\n    {\n      \" has\": -2.8233764,\n      \" is\": -0.31535134,\n      \" its\": -2.3826683\n    },\n    {\n      \" headquartered\": -0.55109984,\n      \" one\": -2.1002703,\n      \" the\": -1.4486494\n    },\n    {\n      \" at\": -5.869949,\n      \" in\": -0.0032031164,\n      \" near\": -8.5726385\n    },\n    {\n      \" Brent\": -0.545463,\n      \" London\": -0.92052215,\n      \" the\": -4.2185493\n    },\n    {\n      \" and\": -5.981371,\n      \",\": -0.16638732,\n      \".\": -1.8980939\n    },\n    {\n      \" England\": -0.32616717,\n      \" UK\": -3.0831795,\n      \" United\": -1.5094594\n    },\n    {\n      \" and\": -6.7056193,\n      \",\": -4.2434745,\n      \".\": -0.017101035\n    },\n    {\n      \" G\": -1.9666257,\n      \" It\": -1.5737484,\n      \" The\": -0.74378455\n    },\n    {\n      \"<|endoftext|>\": -11.697117,\n      \"a\": -12.103811,\n      \"ax\": -2.987608e-05\n    },\n    {\n      \"o\": -0.0008642354,\n      \"oS\": -9.737364,\n      \"os\": -7.136099\n    },\n    {\n      \" Smith\": -7.3521976,\n      \" was\": -6.813496,\n      \"Smith\": -0.0022986291\n    },\n    {\n      \" K\": -11.677342,\n      \"K\": -0.00015887116,\n      \"k\": -8.871586\n    },\n    {\n      \"lein\": -8.691501,\n      \"line\": -0.00022891893,\n      \"lines\": -11.055365\n    },\n    {\n      \" is\": -1.1443236,\n      \" pl\": -1.3602297,\n      \" was\": -1.4136803\n    },\n    {\n      \" a\": -2.6645842,\n      \" one\": -0.46844757,\n      \" the\": -1.3040093\n    },\n    {\n      \" of\": -0.0017496287,\n      \" the\": -6.3675466,\n      \"of\": -11.86005\n    },\n    {\n      \" largest\": -8.677003,\n      \" the\": -0.0009579596,\n      \" world\": -7.5316787\n    },\n    {\n      \" largest\": -2.0550342,\n      \" leading\": -4.3443274,\n      \" world\": -0.17951918\n    },\n    {\n      \" leaders\": -7.900029,\n      \"'s\": -0.5169886,\n      \"bytes:\\\\xe2\\\\x80\": -0.9091757\n    },\n    {\n      \" largest\": -1.3352236,\n      \" leading\": -0.40709805,\n      \" seven\": -3.4403\n    },\n    {\n      \" healthcare\": -7.261546,\n      \" pharmaceutical\": -5.141404,\n      \" research\": -0.0088511435\n    },\n    {\n      \" and\": -8.222003,\n      \" based\": -5.08583,\n      \"-\": -0.0067133284\n    },\n    {\n      \"based\": -0.0017455689,\n      \"driven\": -8.219348,\n      \"focused\": -6.8067236\n    },\n    {\n      \" healthcare\": -5.020145,\n      \" pharm\": -6.0729623,\n      \" pharmaceutical\": -0.015499245\n    },\n    {\n      \" and\": -0.11081256,\n      \" companies\": -2.365062,\n      \",\": -4.9799953\n    },\n    {\n      \" consumer\": -5.0232387,\n      \" health\": -4.060782,\n      \" healthcare\": -0.024695272\n    },\n    {\n      \" businesses\": -8.158866,\n      \" companies\": -0.0020262394,\n      \" groups\": -6.855477\n    },\n    {\n      \" and\": -1.3939976,\n      \",\": -0.98580974,\n      \".\": -1.054438\n    },\n    {\n      \" It\": -0.5256704,\n      \" Its\": -2.462621,\n      \" The\": -1.5474467\n    },\n    {\n      \" develops\": -2.227209,\n      \" has\": -1.5331764,\n      \" is\": -1.1811619\n    },\n    {\n      \" a\": -0.42184502,\n      \" operations\": -2.613295,\n      \" three\": -2.0726342\n    },\n    {\n      \" divers\": -2.0789366,\n      \" portfolio\": -1.6970577,\n      \" presence\": -1.5555992\n    },\n    {\n      \" network\": -3.2527845,\n      \" portfolio\": -2.3858016,\n      \" presence\": -0.189255\n    },\n    {\n      \" in\": -0.2724072,\n      \" with\": -2.4606776,\n      \",\": -2.4177947\n    },\n    {\n      \" 150\": -5.062854,\n      \" more\": -0.4235033,\n      \" over\": -1.217995\n    },\n    {\n      \" countries\": -10.758285,\n      \" than\": -6.9453374e-05,\n      \" then\": -11.223376\n    },\n    {\n      \" 100\": -4.20143,\n      \" 140\": -4.372189,\n      \" 150\": -0.05317205\n    },\n    {\n      \" countries\": -0.0028111702,\n      \" markets\": -5.9403543,\n      \" nations\": -9.698894\n    },\n    {\n      \" and\": -0.84120345,\n      \",\": -0.87091434,\n      \".\": -2.516134\n    },\n    {\n      \" and\": -0.94684345,\n      \" including\": -3.2292187,\n      \" with\": -0.70785844\n    },\n    {\n      \" a\": -1.775525,\n      \" over\": -1.4545448,\n      \" products\": -1.6566132\n    },\n    {\n      \" and\": -1.701691,\n      \" ranging\": -2.113828,\n      \" sold\": -1.1725172\n    }\n  ],\n  \"text_offset\": [\n    9,\n    17,\n    32,\n    33,\n    36,\n    40,\n    43,\n    44,\n    53,\n    57,\n    66,\n    77,\n    85,\n    86,\n    89,\n    98,\n    107,\n    108,\n    112,\n    115,\n    129,\n    132,\n    139,\n    140,\n    148,\n    149,\n    152,\n    154,\n    155,\n    160,\n    161,\n    165,\n    168,\n    172,\n    175,\n    179,\n    185,\n    187,\n    195,\n    204,\n    205,\n    210,\n    225,\n    229,\n    240,\n    250,\n    251,\n    254,\n    258,\n    260,\n    267,\n    276,\n    279,\n    284,\n    289,\n    293,\n    303,\n    304,\n    309,\n    318\n  ]\n}\nresponse:   British pharmaceutical, biologics, vaccines and consumer healthcare company. It operates globally, and is headquartered in London, England. GlaxoSmithKline is one of the world's leading research-based pharmaceutical and healthcare companies. It has a global presence in more than 150 countries, with products ranging\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1692115885593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence_penalty\n",
        "\n",
        "Defaults to 0 ->o there is really no penalty or reward for the same token appearing multiple times. \n",
        "\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on ** whether they appear in the text so far **, increasing the model's likelihood to talk about new topics.\n",
        "\n",
        "Smaller values (minimum -2) decrease the penalty and increase the chances of a token appearing, while higher values (maximum 2) increase the penalty and decrease the chances of a token appearing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            presence_penalty=2\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrmPCXaimICLjSaLqGvgeDn0hDOL\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119157,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" British multinational pharmaceutical company headquartered in London, United Kingdom. Founded in 1873 as a small consumer goods business, by the end of 2019 it was the world's sixth largest drug company (measured by 2020 revenue).\\n\\nGSK is a global leader in joint health, respiratory and HIV treatments\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 60,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 65\n  }\n}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119158513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            presence_penalty=-2\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrmm00rXFbZhO7f0yfwIUoXHE5an\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119180,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" global science-led healthcare company based in the United Kingdom. The company is the world\\u2019s largest and the most innovative in the field of pharmaceuticals and consumer healthcare. The company is involved in the development, manufacturing and marketing of pharmaceuticals, vaccines, and consumer healthcare products. GSK is\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 60,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 65\n  }\n}\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119181426
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Frequency_penalty\n",
        "\n",
        "Defaults to 0\n",
        "\n",
        "Number between -2.0 and 2.0. Positive values ** penalize new tokens based on their existing frequency in the text so far **, decreasing the model's likelihood to repeat the same line verbatim."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Best_of\n",
        "\n",
        "Defaults to 1\n",
        "\n",
        "This parameter tells the language model to generate multiple completions and return the best one, which is the one with the highest log probability per token.\n",
        "\n",
        "\n",
        "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", #This parameter cannot be used with gpt-35-turbo.\n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            best_of = 3,\n",
        "        )\n",
        "\n",
        "print(response)\n",
        "#Notice that we only received one completion, which is obvious because the other completions were generated on the server and only the best one was returned. "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nr91HvImNPIZbrrGQnLRfSHmoCNi\",\n  \"object\": \"text_completion\",\n  \"created\": 1692116715,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" British multinational pharmaceutical company headquartered in Brentford, London, England. The company was established in 2000 by the merger of Glaxo Wellcome and SmithKline Beecham. GSK is the world's sixth-largest pharmaceutical company, one of the few that produces both prescription medications and over-\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 180,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 185\n  }\n}\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692116716833
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logit_bias\n",
        "\n",
        "Defaults to null\n",
        "\n",
        "The logit_bias request parameter is used to modify the likelihood of specified tokens appearing in the completion. We can use this parameter to provide hints to the language model about which tokens we want or don’t want to appear in the completion. It basically allows us to make the model more biased towards certain keywords or topics."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-100 bias, which should completely prevent them from appearing.\n",
        "# 100 bias will show only that word\n",
        "response = openai.Completion.create(\n",
        "            engine=\"gpt-35-turbo\", #This parameter cannot be used with gpt-35-turbo.\n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=60,\n",
        "            logit_bias={\"39163\":-100, \"9776\": 10}\n",
        "        )\n",
        "\n",
        "print(response)\n",
        "#39163 for England\n",
        "#10 for was"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nroSXHqFSCPy5jvH0qT0SwZ1puZI\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119284,\n  \"model\": \"gpt-35-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"300-year-old company with internal processes and an innovation culture designed for bricks-and-mortar co-location of research and development activities, which has been experimenting with digitization since the first installation of a computer system in the 1970s. GSK was in a position to go even further in integrating digital\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 60,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 65\n  }\n}\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119287026
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max Tokens"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Charging happens based on how many tokens you spend. it’s important to structure your Completion prompts specifically to return what you need and set token limits. Any excessive information that a Completion returns is waste that consumes unecessary tokens."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrqYs47j8b4zyfCpK16C6kHcz3aw\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119414,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" British multinational pharmaceutical company headquartered in Brentford, England.\",\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 11,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 16\n  }\n}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119414674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=5\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrq4jCO6ZXX0bZttnj69ojUXXFW3\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119384,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" British multinational pharmaceutical company and\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 5,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 10\n  }\n}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119384702
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Echo and Stop"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the echo parameter to true, you’re asking the language model to return the prompt embedded within the completion. This is useful for debugging."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=5,\n",
        "            echo =True\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrtilKDWD2TtWaaqf1RCc6tJoTWd\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119610,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \"GSK is a  multinational pharmaceutical company headquartered in\",\n      \"index\": 0,\n      \"finish_reason\": \"length\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 5,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 10\n  }\n}\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119609958
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ** stop ** parameter allows you to specify up to 4 sequences of text on which the language model will halt and return the result. This is useful for specifying early termination triggers for the language model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "            engine=\"textdavinci003yk\", \n",
        "            prompt='GSK is a ',\n",
        "            max_tokens=5,\n",
        "            stop=\"company\"\n",
        "        )\n",
        "\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"cmpl-7nrvRJjiiyVge0sAPRVMzQ2H2Qh9R\",\n  \"object\": \"text_completion\",\n  \"created\": 1692119717,\n  \"model\": \"text-davinci-003\",\n  \"choices\": [\n    {\n      \"text\": \" multinational pharmaceutical \",\n      \"index\": 0,\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"usage\": {\n    \"completion_tokens\": 3,\n    \"prompt_tokens\": 5,\n    \"total_tokens\": 8\n  }\n}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692119717954
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/reference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}